# LLM Configuration
# Configuration for LLM-based reranking

llm:
  provider: none  # openai | anthropic | ollama | none
  enabled: false
  model: "gpt-4o-mini"
  cache_enabled: true
  # api_key: Set via environment variable (OPENAI_API_KEY, ANTHROPIC_API_KEY)
  # base_url: For Ollama, defaults to http://localhost:11434

# OpenAI Configuration
# Set OPENAI_API_KEY environment variable
# openai:
#   api_key: ${OPENAI_API_KEY}
#   model: "gpt-4o-mini"

# Anthropic Configuration
# Set ANTHROPIC_API_KEY environment variable
# anthropic:
#   api_key: ${ANTHROPIC_API_KEY}
#   model: "claude-3-5-sonnet-20241022"

# Ollama Configuration
# ollama:
#   base_url: "http://localhost:11434"
#   model: "llama2"

